{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fibermagic.IO.NeurophotometricsIO import extract_leds\n",
    "import os\n",
    "import pathlib\n",
    "import copy\n",
    "from detrend import detrend\n",
    "from perievents import perievents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your own base path for the experiment data\n",
    "basepath = '/home/james/Massive/PROJECTDATA/NAcC gDA3m + rAdo1.3 FR20-PR/DATA/'\n",
    "\n",
    "# Replace with the path where you want results saved to.\n",
    "outpath = \"/home/james/Massive/PROJECTDATA/NAcC gDA3m + rAdo1.3 FR20-PR/RESULTS/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_keyfile(keyfile):\n",
    "    \"\"\"Opens a csv file containing the metadata about the experiment and returns it as a data frame.\n",
    "    The columns are expected to be: region, mouse, wave_len, protocol, condition, and include.\n",
    "\n",
    "    Args:\n",
    "        keyfile (pathlib.Path): Pathlib path to the keyfile.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A dataframe of the experiment metadata.\n",
    "    \"\"\"\n",
    "    abspath = keyfile.absolute()\n",
    "    keytable = pd.read_csv(abspath)\n",
    "    return keytable\n",
    "\n",
    "def read_mouse_log(logfile, id):\n",
    "    abspath = logfile.absolute()\n",
    "    logs = pd.read_csv(abspath)\n",
    "    logs = pd.read_csv(abspath)\n",
    "    logs.columns = ['ComputerTimestamp', 'SystemTimestamp', 'animal.ID', 'Event', 'pi.time', 'pc.time', 'datetimestamp']\n",
    "    logs = logs[logs['animal.ID']==id]\n",
    "    return logs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_photometry(filepath, start_timestamp, logs):\n",
    "    from fibermagic.IO.NeurophotometricsIO import extract_leds\n",
    "    df = pd.read_csv(filepath)\n",
    "    # The column renaming assumes that all columns to the right of \"Timestamp\" are photometry columns and that the recording regions are letter-number combinations like \"X0\" or \"R1\"\n",
    "    df = df.rename(columns={'R0':'Region0R','G1':'Region1G'})\n",
    "    df = df.rename(columns={'Timestamp':'SystemTimestamp'})\n",
    "    df = df[df.SystemTimestamp>=logs.iloc[0]['SystemTimestamp']]\n",
    "    if 'Flags' in df.columns:  # legacy fix: Flags were renamed to LedState\n",
    "        df = df.rename(columns={'Flags': 'LedState'})\n",
    "    df = extract_leds(df).dropna()\n",
    "    return df\n",
    "\n",
    "# Convert to long format\n",
    "def convert_to_long(df):\n",
    "    NPM_RED = 560\n",
    "    NPM_GREEN = 470\n",
    "    NPM_ISO = 410\n",
    "    # dirty hack to come around dropped frames until we find better solution -\n",
    "    # it makes about 0.16 s difference\n",
    "    df.FrameCounter = np.arange(0, len(df)) // len(df.wave_len.unique())\n",
    "    df = df.set_index('FrameCounter')\n",
    "    regions = [column for column in df.columns if 'Region' in column]\n",
    "    dfs = list()\n",
    "    for region in regions:\n",
    "        channel = NPM_GREEN if 'G' in region else NPM_RED\n",
    "        sdf = pd.DataFrame(data={\n",
    "            'Region': region,\n",
    "            'Channel': channel,\n",
    "            'Timestamp': df.SystemTimestamp[df.wave_len == channel],\n",
    "            'Signal': df[region][df.wave_len == channel],\n",
    "            'Reference': df[region][df.wave_len == NPM_ISO]\n",
    "        }\n",
    "        )\n",
    "        dfs.append(sdf)\n",
    "    dfs = pd.concat(dfs).reset_index().set_index('Region').dropna()\n",
    "    return dfs\n",
    "\n",
    "\n",
    "def detrend_data(df):\n",
    "    df = convert_to_long(df)\n",
    "    df[\"zdFF\"] = detrend(df, \"Timestamp\", \"Signal\", \"Reference\", \"Channel\", steps=False, method=\"airPLS\", smooth=10, standardize=True)\n",
    "    return df\n",
    "\n",
    "def sync_behavior(logs, detrended):\n",
    "    import copy\n",
    "    logs = logs.rename(columns={'SystemTimestamp':'Timestamp'})\n",
    "    dfsx = copy.deepcopy(detrended)\n",
    "    dfsx = dfsx.reset_index()\n",
    "    logsG = pd.merge_asof(logs, dfsx[dfsx.Channel == 470], on=\"Timestamp\", direction = \"nearest\")\n",
    "    logsG = logsG[['Region', 'Channel', 'FrameCounter', 'Event', 'Timestamp', 'animal.ID']]\n",
    "    logsR = pd.merge_asof(logs, dfsx[dfsx.Channel == 560], on=\"Timestamp\", direction = \"nearest\")\n",
    "    logsR = logsR[['Region', 'Channel', 'FrameCounter', 'Event', 'Timestamp', 'animal.ID']]\n",
    "    slogs = pd.concat([logsR, logsG], axis=0)\n",
    "    slogs = slogs.reset_index(drop=True).set_index(['Region', 'Channel', 'FrameCounter'])\n",
    "    dfsx = dfsx.reset_index().set_index(['Region', 'Channel', 'FrameCounter'])\n",
    "    return dfsx, slogs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiment_dirs(start_path, required_files):\n",
    "    \"\"\"Gets the bottom level folders in the starting folder. \n",
    "    The assumption going forward will be that each folder contains the files `logs.csv`, `photometry.csv` and `mouse_to_region.csv)\n",
    "\n",
    "    Args:\n",
    "        start_path (str): Path to the top-level folder containing the experiment data\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    bottom_level_dirs = []\n",
    "    \n",
    "    for dirpath, dirnames, filenames in os.walk(start_path):\n",
    "        # If the current directory has no subdirectories\n",
    "        if not dirnames:\n",
    "            # Check if all required files are present in the current directory\n",
    "            if all(req_file in filenames for req_file in required_files):\n",
    "                bottom_level_dirs.append(dirpath)\n",
    "    \n",
    "    return bottom_level_dirs\n",
    "\n",
    "\n",
    "def get_experiment_metadata(path):\n",
    "    experiment = []\n",
    "    path = pathlib.Path(path)\n",
    "    keyfile = path / 'region_to_mouse.csv'\n",
    "    metadata = read_keyfile(keyfile)\n",
    "    keep = metadata[metadata['include'] == \"yes\"]\n",
    "    mice = list(keep['mouse'][keep['include'] == \"yes\"].unique())\n",
    "    for mouse_id in mice:\n",
    "        mouse = {}\n",
    "        mouse['id'] = mouse_id\n",
    "        mouse['path'] = path\n",
    "        mouse['wavelengths'] = list(keep['wave_len'][keep['mouse'] == mouse_id].unique())\n",
    "        mouse['regions'] = list(keep['region'][keep['mouse'] == mouse_id].unique())\n",
    "        protocol = list(keep['protocol'][keep['mouse'] == mouse_id].unique())\n",
    "        if len(protocol) == 1:\n",
    "            mouse['protocol'] = protocol[0]\n",
    "        elif len(protocol) > 1:\n",
    "            raise Exception(f\"There are multiple protocols for animal {mouse_id}. That should not be the case. \\nPlease check that 'region_to_mouse.csv' is correct\")\n",
    "        else:\n",
    "            raise Exception(f\"There was no protocol found for amimal {mouse_id}. \\nPlease check that 'region_to_mouse.csv' is correct\")\n",
    "        condition = list(keep['condition'][keep['mouse'] == mouse_id].unique())\n",
    "        if len(condition) == 1:\n",
    "            mouse['condition'] = condition[0]\n",
    "        elif len(condition) > 1:\n",
    "            raise Exception(f\"There are multiple conditions for animal {mouse_id}. That should not be the case. \\nPlease check that 'region_to_mouse.csv' is correct\")\n",
    "        else:\n",
    "            raise Exception(f\"There was no condition found for amimal {mouse_id}. \\nPlease check that 'region_to_mouse.csv' is correct. If there was no treatment, enter 'NaN' or None for treatment\")\n",
    "        experiment.append(mouse)\n",
    "    return experiment\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_files = ['logs.csv', 'photometry.csv', 'region_to_mouse.csv']\n",
    "\n",
    "experiment_paths = get_experiment_dirs(basepath, required_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiments = []\n",
    "\n",
    "for path in experiment_paths:\n",
    "    path = pathlib.Path(path)\n",
    "    experiment = get_experiment_metadata(path)\n",
    "    all_experiments = all_experiments + experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment in all_experiments:\n",
    "    mouse_id = experiment['id']\n",
    "    logfile = experiment['path'] / 'logs.csv'\n",
    "    experiment['logs'] = read_mouse_log(logfile, mouse_id)\n",
    "    start_timestamp = experiment['logs'].iloc[0]['SystemTimestamp']\n",
    "    photometry_file = experiment['path'] / 'photometry.csv'\n",
    "    experiment['photometry'] = get_photometry(photometry_file, start_timestamp, experiment['logs'])\n",
    "    experiment['detrended'] = detrend_data(experiment['photometry'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fibermagic.core.perievents import perievents\n",
    "from perievents import perievents\n",
    "\n",
    "for experiment in all_experiments:\n",
    "    print(experiment['id'])\n",
    "    print(experiment['path'])\n",
    "    dfsx,slogs = sync_behavior(experiment['logs'], experiment['detrended'])\n",
    "    experiment['dfsx'] = dfsx\n",
    "    experiment['slogs'] = slogs\n",
    "    try:\n",
    "        experiment['perievents'] = perievents(dfsx, slogs[slogs.Event=='FD'], window=20, frequency=10)\n",
    "    except Exception as e:\n",
    "        print(f\"***ERROR!!!: {str(e)}\")\n",
    "        experiment['perievents'] = f\"***ERROR!!!: {str(e)}\"\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "output_path = Path(outpath)\n",
    "\n",
    "def save_perievents(experiment, outpath):\n",
    "    if type(experiment['perievents']) == pd.core.frame.DataFrame:\n",
    "        experiment['perievents'].to_csv(f\"{outpath}{experiment['id']}-{experiment['protocol']}-{experiment['condition']}.csv\")\n",
    "\n",
    "for experiment in all_experiments:\n",
    "    save_perievents(experiment, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import kaleido\n",
    "\n",
    "\n",
    "def plot_perievents(experiment, outpath):\n",
    "    if type(experiment['perievents']) == pd.core.frame.DataFrame:\n",
    "        figR = px.scatter(experiment['perievents'].loc['Region0R'].reset_index(), x='Timestamp', y='Trial', color='zdFF', range_color=(-5,5),\n",
    "        color_continuous_scale=['blue', 'grey', 'red'], height=300).update_yaxes(autorange=\"reversed\", title_text='Reward #',\n",
    "        title_font={'size': 20}, tickfont={'size': 18}).update_xaxes(title_text=None, showticklabels=False).update_layout(title={'text':f\"{experiment['condition']}: {experiment['condition']}\", 'x':0.5})\n",
    "        for scatter in figR.data:\n",
    "            scatter.marker.symbol = 'square'\n",
    "        figR.show()\n",
    "        figG = px.scatter(experiment['perievents'].loc['Region1G'].reset_index(), x='Timestamp', y='Trial', color='zdFF', range_color=(-5,5),\n",
    "                        color_continuous_scale=['blue', 'grey', 'red'], height=300).update_yaxes(autorange=\"reversed\", title_font={'size': 20}, tickfont={'size': 18}).update_xaxes(title_text='Time (s)', title_font={'size': 20}, tickfont={'size': 18}).update_layout(title={'text':\"iSPN activity\", 'x':0.5})\n",
    "        for scatter in figG.data:\n",
    "            scatter.marker.symbol = 'square'\n",
    "        figG.show()\n",
    "        from plotly.subplots import make_subplots\n",
    "        fig = make_subplots(rows=2, cols=1, subplot_titles=(experiment['condition'], \"iSPN activity\"), vertical_spacing = 0.1, shared_xaxes=True, shared_yaxes=True)\n",
    "        for trace in figR.data:\n",
    "            fig.add_trace(trace, row=1, col=1)\n",
    "        for trace in figG.data:\n",
    "            fig.add_trace(trace, row=2, col=1)\n",
    "        common_colorscale = [[0, 'blue'], [0.5, 'grey'], [1, 'red']]\n",
    "        coloraxis_range=[-4,4]\n",
    "        fig.update_layout(coloraxis=dict(colorscale=common_colorscale, colorbar_title='Z dF/F', cmin=coloraxis_range[0], cmax=coloraxis_range[1]), height=500)\n",
    "        fig.update_yaxes(autorange='reversed', row=1, col=1, title_text='Reward #', title_font={'size': 16}, tickfont={'size': 14}).update_xaxes(showticklabels=False, row=1, col=1)\n",
    "        fig.update_yaxes(autorange='reversed', row=2, col=1, title_text='Reward #', title_font={'size': 16}, tickfont={'size': 14}).update_xaxes(title=\"Time (s) from reward delivery\", showticklabels=True, title_font={'size': 16}, tickfont={'size': 14}, row=2, col=1)\n",
    "        fig.show()\n",
    "        fig.write_image(f\"{outpath}{experiment['id']}-{experiment['protocol']}-{experiment['condition']}_heatmap.jpg\")\n",
    "\n",
    "for experiment in all_experiments:\n",
    "    plot_perievents(experiment, outpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfiber",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
