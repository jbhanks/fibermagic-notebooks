{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fibermagic.IO.NeurophotometricsIO import extract_leds\n",
    "import os\n",
    "import pathlib\n",
    "import copy\n",
    "from detrend import detrend\n",
    "from perievents import perievents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = '/home/james/Massive/PROJECTDATA/NAcC gDA3m + rAdo1.3 FR20-PR/DATA/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_keyfile(keyfile):\n",
    "    \"\"\"Opens a csv file containing the metadata about the experiment and returns it as a data frame.\n",
    "    The columns are expected to be: region, mouse, wave_len, protocol, condition, and include.\n",
    "\n",
    "    Args:\n",
    "        keyfile (pathlib.Path): Pathlib path to the keyfile.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A dataframe of the experiment metadata.\n",
    "    \"\"\"\n",
    "    abspath = keyfile.absolute()\n",
    "    keytable = pd.read_csv(abspath)\n",
    "    return keytable\n",
    "\n",
    "def read_mouse_log(logfile, id):\n",
    "    abspath = logfile.absolute()\n",
    "    logs = pd.read_csv(abspath)\n",
    "    logs = pd.read_csv(abspath)\n",
    "    logs.columns = ['ComputerTimestamp', 'SystemTimestamp', 'animal.ID', 'Event', 'pi.time', 'pc.time', 'datetimestamp']\n",
    "    logs = logs[logs['animal.ID']==id]\n",
    "    return logs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_photometry(filepath, start_timestamp, logs):\n",
    "    from fibermagic.IO.NeurophotometricsIO import extract_leds\n",
    "    df = pd.read_csv(filepath)\n",
    "    # The column renaming assumes that all columns to the right of \"Timestamp\" are photometry columns and that the recording regions are letter-number combinations like \"X0\" or \"R1\"\n",
    "    df = df.rename(columns={'R0':'Region0R','G1':'Region1G'})\n",
    "    df = df.rename(columns={'Timestamp':'SystemTimestamp'})\n",
    "    df = df[df.SystemTimestamp>=logs.iloc[0]['SystemTimestamp']]\n",
    "    if 'Flags' in df.columns:  # legacy fix: Flags were renamed to LedState\n",
    "        df = df.rename(columns={'Flags': 'LedState'})\n",
    "    df = extract_leds(df).dropna()\n",
    "    return df\n",
    "\n",
    "# Convert to long format\n",
    "def convert_to_long(df):\n",
    "    NPM_RED = 560\n",
    "    NPM_GREEN = 470\n",
    "    NPM_ISO = 410\n",
    "    # dirty hack to come around dropped frames until we find better solution -\n",
    "    # it makes about 0.16 s difference\n",
    "    df.FrameCounter = np.arange(0, len(df)) // len(df.wave_len.unique())\n",
    "    df = df.set_index('FrameCounter')\n",
    "    regions = [column for column in df.columns if 'Region' in column]\n",
    "    dfs = list()\n",
    "    for region in regions:\n",
    "        channel = NPM_GREEN if 'G' in region else NPM_RED\n",
    "        sdf = pd.DataFrame(data={\n",
    "            'Region': region,\n",
    "            'Channel': channel,\n",
    "            'Timestamp': df.SystemTimestamp[df.wave_len == channel],\n",
    "            'Signal': df[region][df.wave_len == channel],\n",
    "            'Reference': df[region][df.wave_len == NPM_ISO]\n",
    "        }\n",
    "        )\n",
    "        dfs.append(sdf)\n",
    "    dfs = pd.concat(dfs).reset_index().set_index('Region').dropna()\n",
    "    return dfs\n",
    "\n",
    "\n",
    "def detrend_data(df):\n",
    "    df = convert_to_long(df)\n",
    "    df[\"zdFF\"] = detrend(df, \"Timestamp\", \"Signal\", \"Reference\", \"Channel\", steps=False, method=\"airPLS\", smooth=10, standardize=True)\n",
    "    return df\n",
    "\n",
    "def sync_behavior(logs, detrended):\n",
    "    import copy\n",
    "    logs = logs.rename(columns={'SystemTimestamp':'Timestamp'})\n",
    "    dfsx = copy.deepcopy(detrended)\n",
    "    dfsx = dfsx.reset_index()\n",
    "    logsG = pd.merge_asof(logs, dfsx[dfsx.Channel == 470], on=\"Timestamp\", direction = \"nearest\")\n",
    "    logsG = logsG[['Region', 'Channel', 'FrameCounter', 'Event', 'Timestamp', 'animal.ID']]\n",
    "    logsR = pd.merge_asof(logs, dfsx[dfsx.Channel == 560], on=\"Timestamp\", direction = \"nearest\")\n",
    "    logsR = logsR[['Region', 'Channel', 'FrameCounter', 'Event', 'Timestamp', 'animal.ID']]\n",
    "    slogs = pd.concat([logsR, logsG], axis=0)\n",
    "    slogs = slogs.reset_index(drop=True).set_index(['Region', 'Channel', 'FrameCounter'])\n",
    "    dfsx = dfsx.reset_index().set_index(['Region', 'Channel', 'FrameCounter'])\n",
    "    return dfsx, slogs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiment_dirs(start_path, required_files):\n",
    "    \"\"\"Gets the bottom level folders in the starting folder. \n",
    "    The assumption going forward will be that each folder contains the files `logs.csv`, `photometry.csv` and `mouse_to_region.csv)\n",
    "\n",
    "    Args:\n",
    "        start_path (str): Path to the top-level folder containing the experiment data\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    bottom_level_dirs = []\n",
    "    \n",
    "    for dirpath, dirnames, filenames in os.walk(start_path):\n",
    "        # If the current directory has no subdirectories\n",
    "        if not dirnames:\n",
    "            # Check if all required files are present in the current directory\n",
    "            if all(req_file in filenames for req_file in required_files):\n",
    "                bottom_level_dirs.append(dirpath)\n",
    "    \n",
    "    return bottom_level_dirs\n",
    "\n",
    "\n",
    "def get_experiment_metadata(path):\n",
    "    experiment = []\n",
    "    path = pathlib.Path(path)\n",
    "    keyfile = path / 'region_to_mouse.csv'\n",
    "    metadata = read_keyfile(keyfile)\n",
    "    keep = metadata[metadata['include'] == \"yes\"]\n",
    "    mice = list(keep['mouse'][keep['include'] == \"yes\"].unique())\n",
    "    for mouse_id in mice:\n",
    "        mouse = {}\n",
    "        mouse['id'] = mouse_id\n",
    "        mouse['path'] = path\n",
    "        mouse['wavelengths'] = list(keep['wave_len'][keep['mouse'] == mouse_id].unique())\n",
    "        mouse['regions'] = list(keep['region'][keep['mouse'] == mouse_id].unique())\n",
    "        protocol = list(keep['protocol'][keep['mouse'] == mouse_id].unique())\n",
    "        if len(protocol) == 1:\n",
    "            mouse['protocol'] = protocol[0]\n",
    "        elif len(protocol) > 1:\n",
    "            raise Exception(f\"There are multiple protocols for animal {mouse_id}. That should not be the case. \\nPlease check that 'region_to_mouse.csv' is correct\")\n",
    "        else:\n",
    "            raise Exception(f\"There was no protocol found for amimal {mouse_id}. \\nPlease check that 'region_to_mouse.csv' is correct\")\n",
    "        condition = list(keep['condition'][keep['mouse'] == mouse_id].unique())\n",
    "        if len(condition) == 1:\n",
    "            mouse['condition'] = condition[0]\n",
    "        elif len(condition) > 1:\n",
    "            raise Exception(f\"There are multiple conditions for animal {mouse_id}. That should not be the case. \\nPlease check that 'region_to_mouse.csv' is correct\")\n",
    "        else:\n",
    "            raise Exception(f\"There was no condition found for amimal {mouse_id}. \\nPlease check that 'region_to_mouse.csv' is correct. If there was no treatment, enter 'NaN' or None for treatment\")\n",
    "        experiment.append(mouse)\n",
    "    return experiment\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_files = ['logs.csv', 'photometry.csv', 'region_to_mouse.csv']\n",
    "\n",
    "experiment_paths = get_experiment_dirs(basepath, required_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiments = []\n",
    "\n",
    "for path in experiment_paths:\n",
    "    path = pathlib.Path(path)\n",
    "    experiment = get_experiment_metadata(path)\n",
    "    all_experiments = all_experiments + experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment in all_experiments:\n",
    "    mouse_id = experiment['id']\n",
    "    logfile = experiment['path'] / 'logs.csv'\n",
    "    experiment['logs'] = read_mouse_log(logfile, mouse_id)\n",
    "    start_timestamp = experiment['logs'].iloc[0]['SystemTimestamp']\n",
    "    photometry_file = experiment['path'] / 'photometry.csv'\n",
    "    experiment['photometry'] = get_photometry(photometry_file, start_timestamp, experiment['logs'])\n",
    "    experiment['detrended'] = detrend_data(experiment['photometry'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fibermagic.core.perievents import perievents\n",
    "from perievents import perievents\n",
    "\n",
    "for experiment in all_experiments:\n",
    "    print(experiment['id'])\n",
    "    print(experiment['path'])\n",
    "    dfsx,slogs = sync_behavior(experiment['logs'], experiment['detrended'])\n",
    "    experiment['dfsx'] = dfsx\n",
    "    print(dfsx.columns)\n",
    "    experiment['slogs'] = slogs\n",
    "    try:\n",
    "        experiment['perievents'] = perievents(dfsx, slogs[slogs.Event=='FD'], window=20, frequency=10)\n",
    "    except Exception as e:\n",
    "        print(f\"***ERROR!!!: {str(e)}\")\n",
    "        experiment['perievents'] = f\"***ERROR!!!: {str(e)}\"\n",
    "        print(e)\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiments[0]['perievents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfiber",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
